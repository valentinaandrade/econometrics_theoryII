---
title: "Ayudantía 4. Selection models - Heckman"
author: "Profesor: Tomás Rau.     Ayudantes: Valentina Andrade y Nicolás Valle"
abstract: "En este ejercicio simularemos datos de modo que conoceremos el GDP, y cómo están seleccionados los datos. Lo que hacemos es verificar cómo afecta la selección a la estimación, y como la propuesta de **Heckman** permite lidiar con este problema. "

date: "12 de abril de 2024"
output:
  prettydoc::html_pretty:
    theme: tactile
    highlight: github
    math: katex

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning =  F, message = F)
pacman::p_load(kableExtra, tidyverse, sampleSelection, sjPlot)
theme_set(theme_classic())
```

## Set del problema


Descripción de los datos:

- Seleccionar aleatoriamente 10,000 observaciones
- educ uniforme entre [0,16]
- age uniforme entre [18,64]
- wearnl = 4.49 + 0.08 * educ + 0.012 * age +  $\varepsilon$

**¿Qué haremos?**

Generaremos datos faltantes para wearnl extraídos de z de la normal estándar [0,1]. 

$$
d^* = -1.5 + 0.15 \times educ + 0.01 \times age + 0.15 \times z + v
$$

$$
\text{wearnl se define como:} 
\begin{cases} 
\text{falta si } d^* \leq 0 \\
\text{informado si } d^* > 0 
\end{cases}
$$

$$
\text{wearnl\_all} = \text{wearnl con observaciones no faltantes}
$$


## Set de los datos 

```{r heckman-setup}
set.seed(123456)

N = 10000
educ = sample(1:16, N, replace = TRUE)
age  = sample(18:64, N, replace = TRUE)

covmat = matrix(c(.46^2, .25*.46, .25*.46, 1), ncol = 2)
errors = mvtnorm::rmvnorm(N, sigma = covmat)
z = rnorm(N)
e = errors[, 1]
v = errors[, 2]

wearnl = 4.49 + .08 * educ + .012 * age + e

d_star = -1.5 + 0.15 * educ + 0.01 * age + 0.15 * z + v

observed_index  = d_star > 0

d = data.frame(wearnl, educ, age, z, observed_index)

```


Ahora miremos el OLS observado y completo

```{r heckman-comparison-models}
# lm basado en datos completos
lm_all = lm(wearnl ~ educ + age, data=d)

# lm basado en datos observados
lm_obs = lm(wearnl ~ educ + age, data=d[observed_index,])

tab_model(lm_all, lm_obs,
          dv.labels = c("LM all", "LM obs"),
          p.style = "stars",
          collapse.ci = TRUE)
```

- Los coeficientes de LM observados son más pequeños, y los errores estándar son distintos

# Selection model by Heckman

## Two way step

- Paso 1: Realiza un modelo probit respecto a si el individuo es observado o no, con el fin de calcular la [razón de Mills inversa](https://es.wikipedia.org/wiki/Raz%C3%B3n_de_Mills#Raz%C3%B3n_de_Mills_inversa), o 'peligro de no selección' (hazard rate).

- Paso 2: Estimar el modelo lineal estándar, incorporando la selección. 

### Paso 1: Modelo Probit

Se ajusta un modelo probit donde la variable dependiente es observed_index, una variable indicadora de si la observación de salario está presente o no. Los predictores son educ, age, y una variable adicional z, que podría representar otras características individuales o contextuales que afectan la probabilidad de observación. El probit se usa para modelar la probabilidad de que observed_index sea 1 (es decir, que el salario sea observado).

```{r heckman-glm}
probit = glm(observed_index ~ educ + age + z,
             data   = d,
             family = binomial(link = 'probit'))

summary(probit)

# ¿Cómo calcular el inverse mills ratio? Mira este link: 
# http://www.stata.com/support/faqs/statistics/inverse-mills-ratio/
probit_lp = predict(probit)
mills0 = dnorm(probit_lp)/pnorm(probit_lp)

summary(mills0)

# Otra forma de hacerlo:
# probit_lp = -predict(probit)
# imr = dnorm(probit_lp)/(1-pnorm(probit_lp))
imr = mills0[observed_index]

summary(imr)
```


Después de estimar el modelo probit, calculas el Inverse Mills Ratio (IMR) para cada observación. El IMR se obtiene dividiendo la densidad de la distribución normal estándar (dnorm(probit_lp)) por la función de distribución acumulativa (pnorm(probit_lp)), donde probit_lp son los valores predichos del modelo probit. Este ratio es crucial para el segundo paso del modelo de Heckman, ya que ajusta las estimaciones por el sesgo de selección.

¿Cómo calcular el inverse mills ratio? Mira este [link](http://www.stata.com/support/faqs/statistics/inverse-mills-ratio/)

```{r heckman-mills}
probit_lp = predict(probit)
mills0 = dnorm(probit_lp)/pnorm(probit_lp)

summary(mills0)

# Otra forma de hacerlo:
# probit_lp = -predict(probit)
# imr = dnorm(probit_lp)/(1-pnorm(probit_lp))
imr = mills0[observed_index]

summary(imr)
```


Observemos la distribución del Inverse Mills Ratio en la muestra: 

```{r heckman-vis}
ggplot2::qplot(imr, geom = 'histogram')
```


Dado que el IMR ajusta por el riesgo de selección, entender su distribución puede darte pistas sobre cuán generalizado está el problema de selección en tus datos. Por ejemplo, una distribución del IMR concentrada cerca de cero sugiere que el riesgo de sesgo de selección es bajo para la mayoría de las observaciones, mientras que una distribución más dispersa o sesgada podría indicar un riesgo variado y potencialmente más significativo de sesgo de selección a través de la muestra.

#### Interpretación: 

- **Modelo Probit**: Los coeficientes del modelo probit te dicen cómo las variables `educ`, `age`, y `z` afectan la probabilidad de que una observación sea incluida (es decir, si el salario se reporta o no). Un coeficiente positivo indica que a medida que el predictor aumenta, también lo hace la probabilidad de observación.

- **IMR**: El IMR ajusta las estimaciones de la *segunda etapa* para el sesgo de selección. Observaciones con un IMR alto y estadísticamente significativo indican un mayor riesgo de selección, y este factor se incorpora en el modelo de resultado para corregir el sesgo asociado con las observaciones no aleatorias.


### Paso 2: Estimación mediante Regresión Lineal

Estimamos el modelo de regresión estándar utilizando la razón de Mills inversa como covariable

```{r heckman-step-2}
lm_select = lm(wearnl ~ educ + age + imr, data = d[observed_index, ])

summary(lm_select)
```

También lo podemos hacer con el paquete <span class="pack" style = "

">sampleSelection</span> directamente. 

```{r heckman-compare-1}
selection_2step = selection(observed_index ~ educ + age + z, wearnl ~ educ + age, 
                            method = '2step')

summary(selection_2step)
```

Los IMR son ligeramente diferentes (4 cifras significativas)

```{r compare-2}
coef(lm_select)['imr'] / summary(lm_select)$sigma        
coef(lm_select)['imr'] / summary(selection_2step)$estimate['sigma', 'Estimate']
```



#   Máxima Verosimilitud 

La siguiente función de verosimilitud toma argumentos de la siguiente manera:

- **par**: los coeficientes de regresión relacionados con los dos modelos, el error estándar residual
- **sigma** y rho para la estimación de correlación
- **X**: matriz de modelo de datos observados para el modelo de regresión lineal
- **Z**: matriz de modelo de datos completos para el modelo probit
- **y**: la variable objetivo
- **observed_index**: un índice que denota si se observa el outcome

```{r select-ll}
select_ll <- function(par, X, Z, y, observed_index) {
  gamma     = par[1:4]
  lp_probit = Z %*% gamma
  
  beta  = par[5:7]
  lp_lm = X %*% beta
  
  sigma = par[8]
  rho   = par[9]
  
  ll = sum(log(1-pnorm(lp_probit[!observed_index]))) +
    - log(sigma) +
    sum(dnorm(y, mean = lp_lm, sd = sigma, log = TRUE)) +
    sum(
      pnorm((lp_probit[observed_index] + rho/sigma * (y-lp_lm)) / sqrt(1-rho^2), 
            log.p = TRUE)
    )
  
  -ll
}
```

```{r heckman-initialize}
X = model.matrix(lm_select)
Z = model.matrix(probit)

# valores iniciales
init = c(coef(probit), coef(lm_select)[-4],  1, 0)
```

Estimar mediante <span class="func" style = "">optim</span>. Sin límites para sigma y rho recibirás advertencias, pero funciona de todos modos.

```{r heckman-estimate}
fit_unbounded = optim(
  init,
  select_ll,
  X = X[, -4],
  Z = Z,
  y = wearnl[observed_index],
  observed_index = observed_index,
  method  = 'BFGS',
  control = list(maxit = 1000, reltol = 1e-15),
  hessian = T
)
```

### Comparación


```{r selection-package} 
selection_ml = selection(observed_index ~ educ + age + z, wearnl ~ educ + age, 
                         method = 'ml')
# summary(selection_ml)
```

Ahora comparamos los resultados de los diferentes enfoques de estimación.

```{r heckman-compare, echo=FALSE}
# comparar coeficientes
tibble(
  model = rep(c('probit', 'lm', 'ambos'), c(4, 4, 1)),
  par   = names(coef(selection_ml)),
  sampselpack_ml = coef(selection_ml),
  unbounded_ml   = fit_unbounded$par,
  explicit_twostep = c(
    coef(probit),
    coef(lm_select)[1:3],
    summary(lm_select)$sigma,
    coef(lm_select)['imr'] / summary(lm_select)$sigma
  ),
  sampselpack_2step = coef(selection_2step)[-8]
) %>%
  kable()

# comparar errores estándar
tibble(
  model = rep(c('probit', 'lm', 'ambos'), c(4, 4, 1)),
  par   = names(coef(selection_ml)),
  sampselpack_ml = sqrt(diag(solve(
    -selection_ml$hessian
  ))),
  unbounded_ml = sqrt(diag(solve(
    fit_unbounded$hessian
  ))),
  explicit_twostep = c(
    summary(probit)$coefficients[, 2],
    summary(lm_select)$coefficients[-4, 2],
    NA,
    NA
  ),
  sampselpack_2step = summary(selection_2step)$estimate[-8, 2]
) %>%
  kable()
```

## Fuente

Código original disponible en https://github.com/m-clark/Miscellaneous-R-Code/blob/master/ModelFitting/heckman_selection.R

```
